{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "import immrax as irx\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "from pathlib import Path\n",
    "import optax\n",
    "from functools import partial \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Rectangle\n",
    "from immutabledict import immutabledict\n",
    "import jax.experimental.compilation_cache.compilation_cache as cc\n",
    "import os\n",
    "from jax.scipy.linalg import block_diag\n",
    "from time import time\n",
    "\n",
    "device = 'gpu'\n",
    "\n",
    "# if device == 'gpu' :\n",
    "#     cc.initialize_cache('cache')\n",
    "\n",
    "def jit (f, *args, **kwargs) :\n",
    "    kwargs.setdefault('backend', device)\n",
    "    return eqx.filter_jit(f, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_LIM = 10.\n",
    "\n",
    "class Platoon(irx.OpenLoopSystem) :\n",
    "    \"\"\"A platoon of N vehicles\n",
    "\n",
    "    The state is [x1, v1, x2, v2, ..., xN, vN]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__ (self, N) :\n",
    "        self.evolution = 'continuous'\n",
    "        self.xlen = 2*N\n",
    "        self.N = N\n",
    "\n",
    "    def f (self, t, x, u, w) :\n",
    "        xdot = jnp.zeros(2*self.N)\n",
    "        xdot = xdot.at[0::2].set(x[1::2])\n",
    "        xdot = xdot.at[1::2].set(U_LIM*jnp.tanh(u/U_LIM)*(1+w))\n",
    "        return xdot\n",
    "\n",
    "# f for one vehicle\n",
    "def f_veh (t, x, u, w) :\n",
    "    return jnp.array([x[1], U_LIM*jnp.tanh(u[0]/U_LIM)*(1+w[0])])\n",
    "\n",
    "veh_mjacM = irx.mjacM(f_veh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicles: 28\n",
      "Number of states: 56\n",
      "Number of lifted states: 84\n"
     ]
    }
   ],
   "source": [
    "N = 3*9 + 1\n",
    "sys = Platoon(N)\n",
    "\n",
    "print(f'Number of vehicles: {N}')\n",
    "print(f'Number of states: {sys.xlen}')\n",
    "\n",
    "Hblk = jnp.array([\n",
    "    [1., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 1.]\n",
    "])\n",
    "H = jnp.kron(jnp.eye(N), Hblk)\n",
    "yblk = 0.1*jnp.array([1., 1., 0.8])\n",
    "# ypre = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.arange(N)**2+1, yblk))\n",
    "_ypre = jnp.empty(N)\n",
    "_ypre = _ypre.at[::3].set(1.); _ypre = _ypre.at[1::3].set(3.); _ypre = _ypre.at[2::3].set(9.)\n",
    "ypre = irx.icentpert(jnp.zeros(len(H)), jnp.kron(_ypre, yblk))\n",
    "# ypre = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.array([1., 3., 1.]), yblk))\n",
    "# y = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.array([1., 1.5, 1.]), yblk))\n",
    "# y = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.array([1., 3.]), yblk))\n",
    "# ypre = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.array([1., 3., 20., 3., 1.]), yblk))\n",
    "# y = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.ones(N), yblk))\n",
    "# y = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.array([1., 3., 9.]), yblk))\n",
    "# y = irx.icentpert(jnp.zeros(len(H)), jnp.kron(jnp.ones(N), yblk))\n",
    "trainable = jnp.kron(jnp.ones(N), jnp.array([0,0,0])).astype(bool)\n",
    "# print(trainable)\n",
    "ywhere = jnp.where(trainable)\n",
    "w = irx.icentpert(jnp.zeros(N), 0.1)\n",
    "\n",
    "print(f'Number of lifted states: {len(H)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Setup pseudoinverse, get null space, and make IH function.\n",
    "\n",
    "Hblkdag = jnp.linalg.pinv(Hblk)\n",
    "Hdag = jnp.kron(jnp.eye(N), Hblkdag)\n",
    "NHblk = irx.utils.null_space(Hblk.T)\n",
    "NH = jnp.kron(jnp.eye(N), NHblk)\n",
    "\n",
    "print(jnp.all(jnp.isclose(NH.T @ H, 0., atol=1e-5)))\n",
    "\n",
    "IH = jit(irx.utils.I_refine(NH.T))\n",
    "# ypre = IH(ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878\n",
      " -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878\n",
      " -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878\n",
      " -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878 -0.06237878\n",
      " -0.06237878 -0.06237878 -0.06237878 -0.06237878]\n"
     ]
    }
   ],
   "source": [
    "# Setup neural network controller\n",
    "\n",
    "os.system(f'mkdir -p {N}-platoon')\n",
    "arch = '6 32 relu 32 relu 32 relu 1'\n",
    "os.system('echo ' + arch + f' > {N}-platoon/arch.txt')\n",
    "\n",
    "class PlatoonControl (irx.Control, eqx.Module) :\n",
    "    net: list\n",
    "    out_len:int = eqx.field(static=True)\n",
    "\n",
    "    def __init__ (self, key=jax.random.key(0)) :\n",
    "        self.net = irx.NeuralNetwork(f'{N}-platoon', False, key=key)\n",
    "        self.out_len = N\n",
    "    \n",
    "    def __call__ (self, x) :\n",
    "        x = x.reshape((N, 2))\n",
    "\n",
    "        # Setup relative inputs for the network for vmap\n",
    "        X = jnp.zeros((N, 6))\n",
    "        X = X.at[1:,2:4].set(x[:-1] - x[1:])  # relative position to the previous vehicle\n",
    "        X = X.at[:-1,4:6].set(x[:-1] - x[1:])  # relative position to the next vehicle\n",
    "        X = X.at[::3, :2].set(x[::3])  # absolute position for every 3-rd vehicle\n",
    "        X = X.at[::3, 2:].set(0.) \n",
    "        X = X.at[3::3, 2:4].set(x[:-1:3] - x[3::3])  # relative position to the previous third vehicle\n",
    "        X = X.at[:-1:3, 4:6].set(x[:-1:3] - x[3::3])  # relative position to the next third vehicle\n",
    "       \n",
    "        # vmap over neural net\n",
    "        def apply_net (X) :\n",
    "            return self.net(X)[0]\n",
    "        return jax.vmap(apply_net)(X)\n",
    "\n",
    "    def u (self, t, x) :\n",
    "        return self(x)\n",
    "\n",
    "    def save (self) :\n",
    "        self.net.save()\n",
    "\n",
    "net = PlatoonControl()\n",
    "print(net(jnp.zeros(2*N)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the lifted embedding system\n",
    "\n",
    "# Single lifted vehicle dynamics\n",
    "def g_veh (t, x, u, w, *, Hblkp) :\n",
    "    return Hblk @ f_veh(t, Hblkp@x, u, w)\n",
    "\n",
    "g_veh_mjacM = irx.jacM(g_veh)\n",
    "\n",
    "def wrapped_g_veh_mjacM (t, x, u, w, Hblkp) :\n",
    "    return g_veh_mjacM(t, x, u, w, Hblkp=Hblkp)\n",
    "\n",
    "def build_lifted_clsys (net, eta) :\n",
    "    Hp = Hdag + eta@NH.T\n",
    "    lifted_sys = irx.LiftedSystem(sys, H, Hp)\n",
    "\n",
    "    def lifted_net (y) :\n",
    "        return net(Hp @ y)\n",
    "    lifted_net.u = lambda t, y : lifted_net(y)\n",
    "\n",
    "    lifted_net.out_len = net.out_len\n",
    "    return irx.NNCSystem(lifted_sys, lifted_net)\n",
    "\n",
    "\n",
    "def build_lifted_embsys (net, eta) :\n",
    "    Hp = Hdag + eta@NH.T\n",
    "    lifted_sys = irx.LiftedSystem(sys, H, Hp)\n",
    "\n",
    "    Hblkps = jnp.array([Hblkdag + eta[i:i+2,(i,)] @ NHblk.T for i in range(0, 2*N, 2)])\n",
    "\n",
    "    # Block diagonal mjacM for the platoon, more efficient to build block diagonally\n",
    "    def lifted_mjacM (t, y, u, w, **kwargs) :\n",
    "        # vmap over vehicles using g_veh_mjacM and Sblkps\n",
    "        inputs = (t, y.reshape((N, 3)), u.reshape((N, 1)), w.reshape((N, 1)), Hblkps)\n",
    "        # mjacMs = jax.vmap(wrapped_g_veh_mjacM, in_axes=(None, 0, 0, 0, 0))(*inputs)[0]\n",
    "        mjacMs = jax.vmap(wrapped_g_veh_mjacM, in_axes=(None, 0, 0, 0, 0))(*inputs)\n",
    "        Mt = jnp.zeros((3*N, 1))\n",
    "        Mx = irx.natif(block_diag)(*[mjacMs[1][i] for i in range(N)])\n",
    "        Mu = irx.natif(block_diag)(*[mjacMs[2][i] for i in range(N)])\n",
    "        Mw = irx.natif(block_diag)(*[mjacMs[3][i] for i in range(N)])\n",
    "        return [[Mt, Mx, Mu, Mw]]\n",
    "\n",
    "    def lifted_net (y) :\n",
    "        return net(Hp @ y)\n",
    "\n",
    "    lifted_net.out_len = net.out_len\n",
    "    lifted_net.u = lambda t, y : lifted_net(y)\n",
    "    lifted_clsys = irx.NNCSystem(lifted_sys, lifted_net)\n",
    "    lifted_embsys = irx.NNCEmbeddingSystem(lifted_clsys, 'crown', 'local', 'local', lifted_mjacM)\n",
    "    return lifted_embsys\n",
    "\n",
    "eta = jnp.zeros((2*N, len(NH.T)))\n",
    "oly = ypre.upper[ywhere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fake permutations and corners for the lifted embedding system\n",
    "permutations = irx.standard_permutation(1 + len(H) + N + N)\n",
    "corners = irx.bot_corner(1 + len(H) + N + N)\n",
    "\n",
    "# Lifted embedding system evaluation\n",
    "def EH (net:irx.NeuralNetwork, eta:jax.Array=eta, y=ypre) :\n",
    "    lifted_embsys = build_lifted_embsys(net, eta)\n",
    "    return lifted_embsys.E(irx.interval([0.]), irx.i2ut(y), w,\n",
    "        permutations=permutations, corners=corners, refine=IH)\n",
    "\n",
    "def relu_eps (x, eps) :\n",
    "    return jax.nn.relu(x + eps)\n",
    "\n",
    "# Loss from the lifted embedding system evaluation\n",
    "def LH (net:irx.NeuralNetwork, eta:jax.Array=eta, y=ypre, epsl:float=0.02, epsu:float=0.02) :\n",
    "    E = EH(net, eta, y)\n",
    "    return jnp.sum(jax.vmap(partial(relu_eps, eps=epsl))(-E[:len(H)])) \\\n",
    "         + jnp.sum(jax.vmap(partial(relu_eps, eps=epsu))( E[len(H):])) \n",
    "\n",
    "def oly_to_y (oly) :\n",
    "    return irx.interval(ypre.lower.at[trainable].set(-oly), ypre.upper.at[trainable].set(oly))\n",
    "\n",
    "def loss(params) :\n",
    "    net, eta, oly = params\n",
    "    return LH(net, eta, oly_to_y(oly)) + 100.*jnp.sum(jax.vmap(partial(relu_eps, eps=0.05))(-oly)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 10:21:39.628425: E external/xla/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module jit_make_step] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "2024-05-22 10:21:45.380135: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 2m5.751888362s\n",
      "\n",
      "********************************\n",
      "[Compiling module jit_make_step] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to JIT make_step: 477.7850890159607\n"
     ]
    }
   ],
   "source": [
    "optim = optax.adam(0.001)\n",
    "\n",
    "# A step of the optimizer\n",
    "@jit\n",
    "def make_step (params, opt_state) :\n",
    "    loss_value, grads = eqx.filter_value_and_grad(loss)(params)\n",
    "    updates, opt_state = optim.update(grads, opt_state, params)\n",
    "    params = eqx.apply_updates(params, updates)\n",
    "    net, eta, oly = params\n",
    "    return (params, opt_state, loss_value, EH(net, eta, oly_to_y(oly)))\n",
    "\n",
    "params = (net, eta, oly)\n",
    "\n",
    "t0 = time()\n",
    "make_step(params, optim.init(eqx.filter(params, eqx.is_array)))\n",
    "tf = time()\n",
    "print(f'Time to JIT make_step: {tf-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=0, train_loss=43.341426849365234, \n",
      "EHl=[ 0.01944574 -0.05904369 -0.16128539  0.0606235  -0.23480365 -0.57062554\n",
      "  0.18016829 -0.08125772 -1.0651081   0.01909932 -0.06552102 -0.16911492\n",
      "  0.06025036 -0.2354295  -0.57128537  0.1801683  -0.08127012 -1.0651878\n",
      "  0.01903004 -0.06567524 -0.16936047  0.06025036 -0.23546375 -0.57131946\n",
      "  0.18016827 -0.08132209 -1.0652773   0.01900046 -0.06568238 -0.16943778\n",
      "  0.06025036 -0.235473   -0.571329    0.18016827 -0.08132208 -1.0652771\n",
      "  0.01900047 -0.06568645 -0.16944396  0.06025036 -0.23540728 -0.5712636\n",
      "  0.18034627 -0.08129533 -1.065523    0.01903005 -0.0656826  -0.16943896\n",
      "  0.0606235  -0.23520131 -0.57081586  0.18034628 -0.08125319 -1.0654159\n",
      "  0.01903005 -0.06568253 -0.16943838  0.06062349 -0.23520131 -0.5708159\n",
      "  0.1803463  -0.08125319 -1.0654159   0.01903004 -0.06566624 -0.1693489\n",
      "  0.0606235  -0.23520131 -0.5708159   0.1803463  -0.08124074 -1.0653808\n",
      "  0.01909933 -0.06554879 -0.16912588  0.0606235  -0.23516697 -0.57057524\n",
      "  0.1803463  -0.08104659 -1.0655118   0.01958429 -0.05851667 -0.15738676], \n",
      "EHu=[-0.02055424 -0.04656631  0.0545497  -0.05937642  0.28016937  0.73358166\n",
      " -0.17983139 -0.0074335   1.1502068  -0.02090064 -0.0360392   0.065597\n",
      " -0.05974956  0.2819277   0.73528165 -0.17983145 -0.00734621  1.1504983\n",
      " -0.02096992 -0.0358421   0.06576621 -0.05974953  0.2820175   0.73537236\n",
      " -0.17983145 -0.00727966  1.1507663  -0.0209995  -0.0358301   0.06570722\n",
      " -0.05974956  0.2820459   0.7354003  -0.17983133 -0.00727968  1.1507663\n",
      " -0.02099951 -0.03582469  0.06571609 -0.0597495   0.28190035  0.73525745\n",
      " -0.17965353 -0.00734559  1.1501254  -0.02096993 -0.03583     0.0657094\n",
      " -0.05937642  0.28132215  0.7349519  -0.17965353 -0.00744824  1.1497477\n",
      " -0.02096993 -0.03583079  0.06570774 -0.05937645  0.28132215  0.7349519\n",
      " -0.17965353 -0.00744824  1.1497478  -0.02096993 -0.03585436  0.06574909\n",
      " -0.05937645  0.28132206  0.7349519  -0.17965353 -0.00746822  1.149665\n",
      " -0.02090064 -0.03603554  0.06560468 -0.05937643  0.2812323   0.7350691\n",
      " -0.17965347 -0.00778295  1.1478689  -0.02041568 -0.04611563  0.05119912]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=100, train_loss=25.23436737060547, \n",
      "EHl=[ 1.98494606e-02 -9.40545928e-03 -1.08959153e-01  7.59862065e-02\n",
      " -2.78361738e-02 -3.13658476e-01  1.94298312e-01 -1.04269292e-03\n",
      " -8.90409172e-01  1.96465645e-02 -1.09804701e-02 -1.18435547e-01\n",
      "  7.60596097e-02 -2.77102292e-02 -3.08126271e-01  1.95184767e-01\n",
      " -7.78204761e-04 -8.90423656e-01  1.98675133e-02 -1.09335203e-02\n",
      " -1.18045732e-01  7.57032484e-02 -2.78011635e-02 -3.08425665e-01\n",
      "  1.94821477e-01 -1.03766739e-03 -8.90859485e-01  1.95889678e-02\n",
      " -1.10029615e-02 -1.18376166e-01  7.63170272e-02 -2.78090890e-02\n",
      " -3.07862073e-01  1.94950417e-01 -8.81454733e-04 -8.90714407e-01\n",
      "  2.07868870e-02 -1.10558588e-02 -1.17244110e-01  7.58509859e-02\n",
      " -2.77669579e-02 -3.08242023e-01  1.95033804e-01 -9.36054450e-04\n",
      " -8.90604258e-01  1.90396830e-02 -1.11433873e-02 -1.19054645e-01\n",
      "  7.60514438e-02 -2.77981721e-02 -3.08059812e-01  1.94338620e-01\n",
      " -9.68445500e-04 -8.91061246e-01  2.06864811e-02 -1.11101773e-02\n",
      " -1.17410973e-01  7.62772411e-02 -2.78417692e-02 -3.07905227e-01\n",
      "  1.94548368e-01 -9.17786325e-04 -8.91045809e-01  2.02832669e-02\n",
      " -1.10415881e-02 -1.17721707e-01  7.62016177e-02 -2.78301686e-02\n",
      " -3.07985663e-01  1.94405600e-01 -1.01322250e-03 -8.91155124e-01\n",
      "  2.02150103e-02 -1.09695662e-02 -1.17993005e-01  7.61694461e-02\n",
      " -2.78886426e-02 -3.08542103e-01  1.96019039e-01 -9.25878063e-04\n",
      " -8.91949892e-01  1.92058198e-02 -1.11368503e-02 -1.10035516e-01], \n",
      "EHu=[-0.0201505  -0.01923579  0.07931117 -0.0440136  -0.01272723  0.2817596\n",
      " -0.16570157 -0.01718463  0.85979056 -0.02035337 -0.01528152  0.07261866\n",
      " -0.04394026 -0.01281523  0.28706607 -0.16481519 -0.01742959  0.8592285\n",
      " -0.02013244 -0.01534944  0.07290911 -0.04429662 -0.01278431  0.28686514\n",
      " -0.1651783  -0.01717973  0.8593877  -0.02041101 -0.01524872  0.07274866\n",
      " -0.04368283 -0.01275064  0.28747368 -0.16504943 -0.01735429  0.85914445\n",
      " -0.01921307 -0.01517191  0.07401022 -0.04414892 -0.01280424  0.2869918\n",
      " -0.16496599 -0.01726571  0.85942227 -0.02096029 -0.01504457  0.07241963\n",
      " -0.0439485  -0.01271005  0.28733128 -0.1656611  -0.01725885  0.8590183\n",
      " -0.01931348 -0.0150929   0.07397704 -0.0437227  -0.01272653  0.28748977\n",
      " -0.16545135 -0.017303    0.8588798  -0.01971669 -0.01519244  0.07349807\n",
      " -0.0437983  -0.01277787  0.2873304  -0.16559416 -0.01718328  0.8590314\n",
      " -0.01978495 -0.01529669  0.07306373 -0.04383051 -0.01272457  0.28690326\n",
      " -0.1639806  -0.01721726  0.85827655 -0.02079416 -0.01510291  0.08110358]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=200, train_loss=20.253780364990234, \n",
      "EHl=[ 0.02044686  0.02974385 -0.06807372  0.07061341  0.023009   -0.2727146\n",
      "  0.20322724  0.06938269 -0.7182734   0.02069888  0.01871609 -0.1023947\n",
      "  0.07060103  0.02256553 -0.2686446   0.20221198  0.0687273  -0.71658045\n",
      "  0.02064978  0.01820148 -0.10381714  0.07157576  0.02316149 -0.26790538\n",
      "  0.20257111  0.07068081 -0.71428573  0.0198194   0.01899278 -0.10364463\n",
      "  0.07143752  0.02340359 -0.2674255   0.20295225  0.07016715 -0.710572\n",
      "  0.019966    0.01963726 -0.10254735  0.07135231  0.02375313 -0.26733732\n",
      "  0.20281328  0.07000096 -0.71166646  0.0199538   0.02006887 -0.10241485\n",
      "  0.07216911  0.02284965 -0.26767603  0.20155537  0.06955345 -0.71552026\n",
      "  0.0196666   0.01996549 -0.10212719  0.07244286  0.02225444 -0.26696593\n",
      "  0.2028842   0.07042851 -0.7120415   0.02061032  0.01948757 -0.10233396\n",
      "  0.07229772  0.02252493 -0.26801696  0.2041831   0.07091226 -0.7146372\n",
      "  0.01973775  0.01982456 -0.10171356  0.07226418  0.023396   -0.26637518\n",
      "  0.20436628  0.07174189 -0.713638    0.0199085   0.02123174 -0.08160093], \n",
      "EHu=[-0.0195531  -0.06210805  0.05204483 -0.0493865  -0.02942584  0.2041267\n",
      " -0.15677261 -0.01981598  0.7097608  -0.01930108 -0.02431253  0.10829937\n",
      " -0.04939881 -0.02868626  0.20833439 -0.1577878  -0.01870519  0.70972157\n",
      " -0.01935018 -0.02320868  0.10935631 -0.04842409 -0.02985118  0.20750491\n",
      " -0.1574285  -0.02206236  0.7050637  -0.02018057 -0.02458693  0.10688846\n",
      " -0.04856244 -0.03034745  0.20700768 -0.15704751 -0.02113754  0.7068335\n",
      " -0.02003396 -0.02589823  0.10541865 -0.0486476  -0.03087902  0.20630318\n",
      " -0.15718651 -0.0209316   0.70754343 -0.02004616 -0.02691676  0.10433458\n",
      " -0.04783079 -0.02930208  0.2087586  -0.15844446 -0.02012217  0.7069183\n",
      " -0.02033339 -0.02669516  0.10420106 -0.04755706 -0.02823064  0.21034712\n",
      " -0.15711552 -0.02165246  0.7059072  -0.01938964 -0.02535523  0.1067521\n",
      " -0.04770219 -0.02855389  0.20977405 -0.15581656 -0.02260518  0.70592964\n",
      " -0.0202622  -0.02658814  0.10454811 -0.04773575 -0.03035542  0.20785117\n",
      " -0.15563345 -0.02317053  0.7039598  -0.02009147 -0.03000279  0.12330125]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=300, train_loss=16.909881591796875, \n",
      "EHl=[ 2.18343902e-02  3.14597450e-02 -4.42734137e-02  7.63042048e-02\n",
      "  1.20985843e-02 -1.99146524e-01  1.93402261e-01  1.11475028e-01\n",
      " -5.53773642e-01  2.05474738e-02 -1.06082566e-03 -1.34278983e-01\n",
      "  8.02656114e-02  1.23829264e-02 -1.90443799e-01  1.91632092e-01\n",
      "  1.14306055e-01 -5.50004303e-01  2.02062968e-02 -3.32617923e-03\n",
      " -1.36729151e-01  8.05507675e-02  1.45889260e-02 -1.87700272e-01\n",
      "  1.93875015e-01  1.08041681e-01 -5.59780121e-01  1.98493414e-02\n",
      "  5.11341495e-04 -1.33088127e-01  7.96986520e-02  1.52728222e-02\n",
      " -1.87238246e-01  1.93366975e-01  1.14536919e-01 -5.49480319e-01\n",
      "  2.08268128e-02 -9.40470770e-03 -1.42996803e-01  8.18858892e-02\n",
      "  1.38216764e-02 -1.86895549e-01  1.92611367e-01  1.14022911e-01\n",
      " -5.48227787e-01  1.98144689e-02 -5.88992098e-03 -1.40504956e-01\n",
      "  8.28767791e-02  1.59542877e-02 -1.83310881e-01  1.95343658e-01\n",
      "  1.13461539e-01 -5.47619402e-01  2.00510044e-02 -2.98010348e-03\n",
      " -1.36345059e-01  8.21314454e-02  1.55193321e-02 -1.84662595e-01\n",
      "  1.94008738e-01  1.08903438e-01 -5.53522110e-01  1.99341681e-02\n",
      " -2.44158716e-03 -1.36502862e-01  7.99736083e-02  1.28865791e-02\n",
      " -1.90399900e-01  1.93253741e-01  1.11823678e-01 -5.54171562e-01\n",
      "  1.90095156e-02 -4.93719196e-03 -1.40267700e-01  8.00708979e-02\n",
      "  9.56056640e-03 -1.94576502e-01  1.94429949e-01  1.09974876e-01\n",
      " -5.56095183e-01  1.93735640e-02  2.97441287e-03 -1.28668085e-01], \n",
      "EHu=[-0.01816557 -0.11813702 -0.01122262 -0.04369578 -0.03059205  0.15852639\n",
      " -0.16659749 -0.02343154  0.5129955  -0.0194525  -0.01166835  0.14458603\n",
      " -0.03973435 -0.03131974  0.16443789 -0.1683675  -0.03059322  0.50668687\n",
      " -0.01979365 -0.00801921  0.14825699 -0.03944905 -0.03567311  0.16003427\n",
      " -0.16612464 -0.01655722  0.52946305 -0.02015062 -0.01442999  0.140327\n",
      " -0.04030125 -0.03696764  0.15734398 -0.16663277 -0.02693111  0.50949615\n",
      " -0.01917315  0.00188479  0.16109803 -0.03811406 -0.03420049  0.16255724\n",
      " -0.16738826 -0.02651113  0.50901157 -0.02018551 -0.00386798  0.1533081\n",
      " -0.0371232  -0.03810298  0.15970051 -0.16465598 -0.02669579  0.5107255\n",
      " -0.01994896 -0.00856152  0.14730167 -0.03786844 -0.03726983  0.16020605\n",
      " -0.16599107 -0.01865715  0.52319807 -0.0200658  -0.00945774  0.14615688\n",
      " -0.04002631 -0.03216037  0.16328329 -0.16674596 -0.02458161  0.51209617\n",
      " -0.02099045 -0.00542626  0.14996615 -0.03992896 -0.02559596  0.17052194\n",
      " -0.16556984 -0.02015984  0.51606953 -0.0206264  -0.01962066  0.15828955]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=400, train_loss=14.63248062133789, \n",
      "EHl=[ 0.02217072  0.05628099 -0.02897627  0.07726002  0.00292834 -0.14557101\n",
      "  0.19710222  0.12096462 -0.38319695  0.02002065  0.00338676 -0.14200427\n",
      "  0.08169736  0.00237684 -0.13202484  0.19708148  0.11735269 -0.38580033\n",
      "  0.01991457  0.01196972 -0.1311671   0.08181643  0.00708923 -0.12715618\n",
      "  0.19570334  0.12008702 -0.38245085  0.01962337  0.01071975 -0.13336676\n",
      "  0.08114786  0.00592202 -0.12923875  0.19620068  0.1169899  -0.3889299\n",
      "  0.02087613  0.00497226 -0.13980363  0.08305053  0.00478643 -0.12910998\n",
      "  0.19667733  0.11502315 -0.39114907  0.01951768  0.00331309 -0.14335851\n",
      "  0.08177154  0.00505072 -0.12982391  0.19656377  0.11695541 -0.38943118\n",
      "  0.02011532  0.00324105 -0.14255634  0.08379629  0.00126998 -0.13204159\n",
      "  0.1950106   0.11432198 -0.3929815   0.01972941  0.00741649 -0.13735123\n",
      "  0.0823943   0.00292762 -0.13302186  0.1968719   0.12129295 -0.38328722\n",
      "  0.01879971  0.00711744 -0.138742    0.08309859  0.00550874 -0.12931344\n",
      "  0.1966231   0.11692712 -0.3905054   0.01991258  0.01134661 -0.13021286], \n",
      "EHu=[-1.7829254e-02 -1.6441783e-01 -3.6483586e-02 -4.2739868e-02\n",
      " -3.4262359e-02  1.3346255e-01 -1.6289747e-01 -2.4526119e-02\n",
      "  4.8278904e-01 -1.9979328e-02  9.1204047e-03  1.8453461e-01\n",
      " -3.8302556e-02 -3.3155024e-02  1.3705289e-01 -1.6291815e-01\n",
      " -1.9091249e-02  4.9308974e-01 -2.0085387e-02 -9.5630884e-03\n",
      "  1.6265196e-01 -3.8183451e-02 -4.2317986e-02  1.2971503e-01\n",
      " -1.6429633e-01 -2.2726059e-02  4.8555005e-01 -2.0376615e-02\n",
      " -6.9233179e-03  1.6563433e-01 -3.8852125e-02 -4.0038288e-02\n",
      "  1.3139686e-01 -1.6379899e-01 -1.8237829e-02  4.9104881e-01\n",
      " -1.9123852e-02  5.6691170e-03  1.8171251e-01 -3.6949411e-02\n",
      " -3.7826568e-02  1.3600063e-01 -1.6332233e-01 -1.3773918e-02\n",
      "  4.9609983e-01 -2.0482294e-02  9.2301369e-03  1.8444985e-01\n",
      " -3.8228422e-02 -3.8341731e-02  1.3289848e-01 -1.6343576e-01\n",
      " -1.6107440e-02  4.9033827e-01 -1.9884646e-02  9.4109178e-03\n",
      "  1.8517333e-01 -3.6203593e-02 -3.0981809e-02  1.4194179e-01\n",
      " -1.6498905e-01 -1.0514736e-02  4.9640113e-01 -2.0270571e-02\n",
      "  2.0450354e-04  1.7298800e-01 -3.7605554e-02 -3.4205288e-02\n",
      "  1.3963136e-01 -1.6312772e-01 -2.4470329e-02  4.8196590e-01\n",
      " -2.1200262e-02  8.6307526e-04  1.7291552e-01 -3.6901355e-02\n",
      " -3.9250076e-02  1.3601696e-01 -1.6337657e-01 -1.4541507e-02\n",
      "  4.9099427e-01 -2.0087406e-02 -8.4321499e-03  1.8261433e-01]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=500, train_loss=10.171205520629883, \n",
      "EHl=[ 0.0216939   0.08219065  0.02756522  0.0746071  -0.05080764 -0.11659547\n",
      "  0.19726485  0.07186213 -0.14584133  0.02013765 -0.00848425 -0.09180867\n",
      "  0.08361027 -0.0398893  -0.08662349  0.19686355  0.07873023 -0.13688844\n",
      "  0.01995341 -0.00728124 -0.09297156  0.08430838 -0.04223744 -0.09590349\n",
      "  0.19561072  0.07393731 -0.14120513  0.02014497  0.00064949 -0.08327941\n",
      "  0.08270958 -0.04794999 -0.10208335  0.1988345   0.06112599 -0.1558615\n",
      "  0.02035797 -0.00661404 -0.0915144   0.08475231 -0.05226051 -0.10393779\n",
      "  0.19854493  0.07143851 -0.14748359  0.02029173  0.00058026 -0.08362458\n",
      "  0.0862828  -0.03987635 -0.09102511  0.19923739  0.07738873 -0.1378997\n",
      "  0.0192499  -0.00960861 -0.09525051  0.08672251 -0.04930916 -0.09967769\n",
      "  0.19909938  0.07250093 -0.14574665  0.0196886  -0.01106178 -0.09716397\n",
      "  0.08633723 -0.04503383 -0.09765668  0.19675586  0.06868292 -0.15637386\n",
      "  0.02002216 -0.00348582 -0.08868246  0.0859911  -0.03832648 -0.09361461\n",
      "  0.19770853  0.08005103 -0.14517859  0.01932637 -0.00706394 -0.09584076], \n",
      "EHu=[-1.8306077e-02 -2.1832210e-01 -1.3030788e-01 -4.5392781e-02\n",
      " -3.0828774e-02  7.2225779e-02 -1.6273481e-01 -7.2979927e-04\n",
      "  4.2761600e-01 -1.9862324e-02 -3.1197667e-02  6.5207660e-02\n",
      " -3.6389679e-02 -4.6531588e-02  7.3619217e-02 -1.6313612e-01\n",
      " -1.1170745e-02  4.2066288e-01 -2.0046569e-02 -3.2885671e-02\n",
      "  6.5675259e-02 -3.5691485e-02 -4.3158114e-02  7.9464883e-02\n",
      " -1.6438901e-01 -5.5067539e-03  4.2578924e-01 -1.9855008e-02\n",
      " -4.5240521e-02  5.1886261e-02 -3.7290365e-02 -3.5054088e-02\n",
      "  8.4814429e-02 -1.6116518e-01  1.9255161e-02  4.4602430e-01\n",
      " -1.9642003e-02 -3.3455193e-02  6.4874351e-02 -3.5247624e-02\n",
      " -2.8466821e-02  9.2148602e-02 -1.6145480e-01  1.5325546e-03\n",
      "  4.2966425e-01 -1.9708253e-02 -4.5211971e-02  5.1913977e-02\n",
      " -3.3717155e-02 -4.6514928e-02  7.7366084e-02 -1.6076225e-01\n",
      " -7.8654289e-03  4.1984969e-01 -2.0750068e-02 -2.8791845e-02\n",
      "  6.7852437e-02 -3.3277407e-02 -3.2948554e-02  8.9615613e-02\n",
      " -1.6090035e-01  1.4925003e-04  4.2996180e-01 -2.0311370e-02\n",
      " -2.6898086e-02  7.0504606e-02 -3.3662722e-02 -3.9131939e-02\n",
      "  8.4699154e-02 -1.6324389e-01  8.6659193e-03  4.3177176e-01\n",
      " -1.9977808e-02 -3.8899779e-02  5.8153331e-02 -3.4008786e-02\n",
      " -4.8724830e-02  7.6496512e-02 -1.6229129e-01 -1.1731744e-02\n",
      "  4.1210097e-01 -2.0673588e-02 -3.3227146e-02  7.5593233e-02]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=600, train_loss=6.218611717224121, \n",
      "EHl=[ 0.01998647  0.20389624  0.18425097  0.07354245 -0.04915575 -0.0539095\n",
      "  0.19348876  0.08974247  0.05489162  0.02110058  0.03116155  0.02630256\n",
      "  0.08295214 -0.07477877 -0.06192698  0.19281502  0.07906576  0.05422449\n",
      "  0.02013157  0.05989533  0.05308168  0.08354668 -0.07503708 -0.06173369\n",
      "  0.19358884  0.07217675  0.05217069  0.01943476  0.06012741  0.05230545\n",
      "  0.08346842 -0.07052544 -0.05688358  0.19356202  0.05997328  0.04842606\n",
      "  0.02012866  0.06080982  0.05438344  0.08554242 -0.06612587 -0.05008721\n",
      "  0.19628526  0.08146499  0.02589011  0.020987    0.04763774  0.04542175\n",
      "  0.0879868  -0.07848001 -0.06094629  0.19654167  0.06957706  0.04445493\n",
      "  0.02064758  0.05751792  0.05410027  0.08663639 -0.06278025 -0.04511348\n",
      "  0.1984472   0.07101773  0.05586642  0.01953318  0.05240347  0.04441541\n",
      "  0.0866266  -0.06947275 -0.05358345  0.19802755  0.05779855  0.03109211\n",
      "  0.01991971  0.07226532  0.06408741  0.08684105 -0.07528004 -0.06044209\n",
      "  0.1994569   0.08019335  0.01355898  0.01975474  0.04604024  0.03030435], \n",
      "EHu=[-0.0200135  -0.3148563  -0.28875595 -0.04645747 -0.00503278  0.00357711\n",
      " -0.16651076 -0.01368856  0.2897355  -0.01889938  0.05987597  0.06139338\n",
      " -0.03704779  0.03222477  0.04775578 -0.16718477  0.00714958  0.2950936\n",
      " -0.01986839 -0.00054264  0.00059271 -0.03645325  0.03565449  0.05077279\n",
      " -0.16641098  0.02104783  0.30025017 -0.0205652  -0.00207567 -0.00086629\n",
      " -0.03653157  0.02853644  0.044622   -0.16643763  0.04567838  0.30470324\n",
      " -0.01987129 -0.00260103 -0.00165641 -0.03445745  0.02028954  0.04242527\n",
      " -0.16371441  0.00254416  0.29133314 -0.01901295  0.02600276  0.02475238\n",
      " -0.03201312  0.04002386  0.05725157 -0.16345805  0.02631378  0.29286224\n",
      " -0.01935238  0.00344181  0.00240886 -0.03336361  0.01432729  0.03766012\n",
      " -0.16155261  0.02348614  0.29610336 -0.02046679  0.0142951   0.01401484\n",
      " -0.03337337  0.02796066  0.04651457 -0.16197222  0.05009401  0.3040204\n",
      " -0.02008026 -0.02468026 -0.02351761 -0.03315887  0.0325166   0.05368084\n",
      " -0.16054285  0.00489175  0.29176623 -0.02024523  0.02558672  0.04435265]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=700, train_loss=2.8523201942443848, \n",
      "EHl=[ 0.01959533  0.24310547  0.23923989  0.08414213 -0.12464235 -0.07981601\n",
      "  0.17144267  0.04976742  0.03139701  0.01963462  0.09430359  0.09325452\n",
      "  0.09314704 -0.12455853 -0.05785623  0.17186178  0.04960539  0.04077393\n",
      "  0.02018788  0.08257736  0.08073203  0.09061164 -0.11362289 -0.05035348\n",
      "  0.17489578  0.06559177  0.05313331  0.01915807  0.04186121  0.038185\n",
      "  0.09156695 -0.13860345 -0.07547036  0.17401437  0.06036028  0.05085191\n",
      "  0.01934972  0.06680588  0.06565455  0.09576961 -0.15000042 -0.0837729\n",
      "  0.17636354  0.02077537  0.00720388  0.01973966  0.08180088  0.08469326\n",
      "  0.09355003 -0.13021319 -0.06281401  0.18230963  0.02315517  0.02011779\n",
      "  0.01992543  0.07985415  0.07659504  0.09500311 -0.13608435 -0.07470499\n",
      "  0.18083438  0.03235963  0.02499038  0.01918625  0.048543    0.04940403\n",
      "  0.09600271 -0.11014628 -0.03380585  0.18143569  0.0545036   0.04031819\n",
      "  0.0189241   0.06702782  0.06410511  0.09120493 -0.12560968 -0.06242637\n",
      "  0.1827802   0.04265048  0.03916448  0.0192221   0.04150323  0.03539149], \n",
      "EHu=[-0.02040464 -0.44098496 -0.4273851  -0.03585784 -0.0244053  -0.06041765\n",
      " -0.18855721 -0.0529418   0.02334595 -0.02036533 -0.10946953 -0.11730015\n",
      " -0.02685285 -0.02476114 -0.05387872 -0.18813801 -0.04810107  0.03572547\n",
      " -0.01981209 -0.08335495 -0.0894233  -0.02938826 -0.04130006 -0.07264334\n",
      " -0.18510413 -0.0791086   0.03344905 -0.0208419   0.00502145 -0.00160909\n",
      " -0.028433   -0.0048992  -0.03427535 -0.18598557 -0.06917596  0.0313834\n",
      " -0.02065026 -0.047279   -0.05677211 -0.02423036  0.0122298  -0.01229072\n",
      " -0.18363625  0.00883031  0.07132995 -0.02026033 -0.0801301  -0.09435999\n",
      " -0.0264499  -0.01769006 -0.04928982 -0.17769003  0.00186789  0.06863654\n",
      " -0.02007454 -0.07518697 -0.08050382 -0.02499683 -0.00943625 -0.03309602\n",
      " -0.17916542 -0.01406193  0.06586099 -0.02081374 -0.00827515 -0.02250385\n",
      " -0.02399722 -0.04433131 -0.07783824 -0.17856407 -0.05687988  0.03662479\n",
      " -0.02107587 -0.0487535  -0.05773592 -0.02879499 -0.0233568  -0.05593538\n",
      " -0.17721957 -0.03433049  0.05200875 -0.02077787  0.00893664  0.0125823 ]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=800, train_loss=2.5960333347320557, \n",
      "EHl=[ 0.01998488  0.34154144  0.34284627  0.09825012 -0.09328075 -0.01633123\n",
      "  0.16204067  0.14928475  0.07014909  0.02020038  0.12398574  0.10823013\n",
      "  0.0998594  -0.12077437 -0.05795448  0.15529174  0.09724671  0.04184029\n",
      "  0.02069886  0.14780626  0.1339083   0.10057401 -0.0970009  -0.03419924\n",
      "  0.15381487  0.13154416  0.05163288  0.01905515  0.09540936  0.0753967\n",
      "  0.100761   -0.1295635  -0.06665123  0.1559208   0.10994171  0.04228491\n",
      "  0.01997377  0.17882305  0.16305631  0.10039848 -0.08892367 -0.02517125\n",
      "  0.15785886  0.1481337   0.06378847  0.02043004  0.14823952  0.13259383\n",
      "  0.10042335 -0.07684942 -0.01278089  0.15905666  0.1293721   0.05337873\n",
      "  0.02107729  0.13619009  0.11644801  0.10063699 -0.11217999 -0.05922899\n",
      "  0.15975758  0.1135931   0.03313592  0.0193708   0.12183665  0.10276021\n",
      "  0.10025662 -0.12339295 -0.05651186  0.16150779  0.10811117  0.02052942\n",
      "  0.01981428  0.13537696  0.11268017  0.10136966 -0.09935334 -0.03065744\n",
      "  0.16303737  0.11022356  0.02927548  0.02000126  0.1393477   0.12170802], \n",
      "EHu=[-2.00150684e-02 -5.52544415e-01 -5.46324492e-01 -2.17498690e-02\n",
      " -3.28774452e-02 -5.91341853e-02 -1.97959125e-01 -2.38056540e-01\n",
      " -2.64323950e-02 -1.97995827e-02 -8.78226757e-02 -7.73165226e-02\n",
      " -2.01405883e-02  5.23000956e-03  2.22861767e-04 -2.04707861e-01\n",
      " -1.36574984e-01 -1.16182566e-02 -1.93011165e-02 -1.37989759e-01\n",
      " -1.28326058e-01 -1.94259286e-02 -2.82431841e-02 -3.34886312e-02\n",
      " -2.06185102e-01 -2.00622320e-01 -2.34726667e-02 -2.09448412e-02\n",
      " -2.44284868e-02 -1.10744238e-02 -1.92389041e-02  1.80928111e-02\n",
      "  1.21079683e-02 -2.04078853e-01 -1.60221219e-01 -1.58228874e-02\n",
      " -2.00261995e-02 -2.02277303e-01 -1.91651106e-01 -1.96014643e-02\n",
      " -3.87876630e-02 -4.41932082e-02 -2.02140808e-01 -2.29316473e-01\n",
      " -2.65669823e-02 -1.95699558e-02 -1.34516597e-01 -1.23940945e-01\n",
      " -1.95765346e-02 -5.68302870e-02 -6.58263564e-02 -2.00943112e-01\n",
      " -1.91470385e-01 -1.81382895e-02 -1.89226791e-02 -1.11671448e-01\n",
      " -9.37669277e-02 -1.93629265e-02 -6.01392984e-03 -5.10740280e-03\n",
      " -2.00242102e-01 -1.60952568e-01 -1.09641552e-02 -2.06291676e-02\n",
      " -7.95540810e-02 -6.75410032e-02 -1.97432935e-02  8.19951296e-03\n",
      " -2.97570229e-03 -1.98491991e-01 -1.49650216e-01 -8.18467140e-03\n",
      " -2.01857015e-02 -1.09033585e-01 -9.07273293e-02 -1.86302513e-02\n",
      " -2.58464813e-02 -3.68402004e-02 -1.96962357e-01 -1.49293423e-01\n",
      " -4.78661060e-03 -1.99987069e-02 -1.17865443e-01 -9.68527794e-02]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=900, train_loss=1.5682111978530884, \n",
      "EHl=[ 0.02085421  0.3098182   0.32528296  0.09871224 -0.11159591 -0.05533031\n",
      "  0.15053606  0.19369352  0.06846312  0.01821595  0.08466756  0.07542604\n",
      "  0.10069431 -0.08477137 -0.01409495  0.14024702  0.17326525  0.06956145\n",
      "  0.01989366  0.08292813  0.07689699  0.09887543 -0.07798279 -0.01667738\n",
      "  0.1401265   0.15560482  0.02794611  0.0203949   0.1107176   0.1063378\n",
      "  0.10056808 -0.09608729 -0.02003887  0.14073038  0.1755284   0.0595552\n",
      "  0.01952228  0.0865906   0.07712796  0.10076126 -0.09953137 -0.02323043\n",
      "  0.139906    0.16301039  0.0491122   0.01868705  0.18474172  0.17430314\n",
      "  0.09935723 -0.07424004 -0.00731008  0.14602171  0.14293435  0.02629668\n",
      "  0.01876215  0.1943854   0.18250717  0.10046013 -0.11682053 -0.0565232\n",
      "  0.13901928  0.13866006  0.0256671   0.01957233  0.13414823  0.12745956\n",
      "  0.10017391 -0.05954885 -0.00077324  0.14584303  0.14964238  0.05089599\n",
      "  0.01916027  0.19355887  0.18644907  0.09794214 -0.07999498 -0.0184689\n",
      "  0.14280665  0.17378709  0.05304751  0.01846384  0.07792012  0.07974883], \n",
      "EHu=[-0.01914576 -0.47379863 -0.48691458 -0.02128768 -0.01532221 -0.02412415\n",
      " -0.20946348 -0.3739527  -0.02938879 -0.02178402 -0.00264978 -0.00883496\n",
      " -0.01930562 -0.05461329 -0.06346047 -0.21975249 -0.33306742 -0.02720094\n",
      " -0.02010632  0.00835311  0.00202775 -0.02112445 -0.06419724 -0.07181561\n",
      " -0.21987313 -0.29586935 -0.02442491 -0.01960507 -0.05969787 -0.06688309\n",
      " -0.0194318  -0.03813159 -0.05415529 -0.21926934 -0.3357771  -0.02947032\n",
      " -0.0204777  -0.00694919 -0.00966597 -0.01923871 -0.02648312 -0.04259312\n",
      " -0.22009379 -0.31082332 -0.02669978 -0.02131291 -0.2098329  -0.2131319\n",
      " -0.02064262 -0.0693953  -0.08265698 -0.21397799 -0.2780336  -0.01581419\n",
      " -0.02123781 -0.2331506  -0.23374796 -0.01953979 -0.00329059 -0.00925487\n",
      " -0.22098035 -0.26401985 -0.01848066 -0.02042764 -0.10702705 -0.11413836\n",
      " -0.01982604 -0.08956671 -0.09723151 -0.21415669 -0.28649855 -0.01390553\n",
      " -0.02083969 -0.2332977  -0.24028552 -0.0220578  -0.06041038 -0.07215917\n",
      " -0.21719307 -0.3289821  -0.0205152  -0.02153613  0.01002491 -0.00638294]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=1000, train_loss=0.5721898078918457, \n",
      "EHl=[ 0.01959039  0.52686167  0.5305046   0.0992566   0.00241105  0.0323489\n",
      "  0.14051715  0.29932082  0.08563049  0.02065956  0.27589008  0.25636393\n",
      "  0.09844421  0.03120157  0.05132234  0.12591235  0.29918802  0.0947684\n",
      "  0.0197982   0.2679982   0.25919753  0.09928431  0.03024476  0.05099382\n",
      "  0.12946385  0.26345617  0.06476849  0.02040742  0.29027987  0.27171612\n",
      "  0.10005226  0.02684086  0.04505057  0.12935826  0.29806274  0.09373671\n",
      "  0.02050529  0.18576093  0.16929683  0.09823256  0.00162778  0.02490796\n",
      "  0.1263067   0.25641495  0.05814689  0.01826859  0.1948992   0.17286628\n",
      "  0.0973407   0.01372483  0.03600768  0.1262507   0.2810619   0.09249124\n",
      "  0.01956222  0.26850682  0.24620876  0.09913566  0.010642    0.03241372\n",
      "  0.12274182  0.24879545  0.05390981  0.02071064  0.25412223  0.2358258\n",
      "  0.10118753 -0.01415566  0.0146997   0.12704794  0.25902075  0.11773917\n",
      "  0.01878658  0.20224433  0.18291193  0.09611633 -0.01368275  0.02008653\n",
      "  0.12395936  0.2885171   0.10463634  0.01871396  0.07350469  0.05848484], \n",
      "EHu=[-0.02040958 -0.65636843 -0.65450484 -0.0207433  -0.04063958 -0.02221805\n",
      " -0.21948266 -0.4443673  -0.01722693 -0.01934043 -0.23635495 -0.2139113\n",
      " -0.02155577 -0.09108871 -0.05553806 -0.23408735 -0.44668728 -0.01955009\n",
      " -0.02020177 -0.222098   -0.2148509  -0.02071574 -0.08913136 -0.05831462\n",
      " -0.23053592 -0.3910452  -0.01091659 -0.01959257 -0.26812625 -0.24680972\n",
      " -0.01994766 -0.08192945 -0.04333544 -0.23064137 -0.44564736 -0.01757395\n",
      " -0.01949467 -0.05395019 -0.03582251 -0.02176738 -0.03672504 -0.01054364\n",
      " -0.233693   -0.37968063 -0.01243949 -0.02173138 -0.07477808 -0.05487561\n",
      " -0.0226593  -0.05971879 -0.03546673 -0.23374909 -0.42999053 -0.01733482\n",
      " -0.02043774 -0.21329093 -0.18956804 -0.02086428 -0.05411738 -0.0260061\n",
      " -0.23725778 -0.36356628 -0.01131618 -0.01928934 -0.19771194 -0.17751157\n",
      " -0.01881242 -0.0134514   0.01448745 -0.2329517  -0.39514464 -0.00974631\n",
      " -0.0212134  -0.08477056 -0.06756759 -0.02388361 -0.0144313  -0.00191873\n",
      " -0.23604035 -0.43943    -0.01601732 -0.02128602  0.18896699  0.20672941]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=1100, train_loss=0.6802524328231812, \n",
      "EHl=[ 2.00496837e-02  5.38582504e-01  5.48272491e-01  9.88668799e-02\n",
      " -3.63953505e-03  8.51616263e-03  1.34350270e-01  3.51699352e-01\n",
      "  7.64085501e-02  2.05261298e-02  2.25541860e-01  2.23028302e-01\n",
      "  9.79422331e-02 -3.08817737e-02  3.29605490e-03  1.21989854e-01\n",
      "  2.93417215e-01  9.26045179e-02  2.00397670e-02  2.36750245e-01\n",
      "  2.25765929e-01  9.80031490e-02 -3.42812203e-02  1.39452517e-04\n",
      "  1.17639549e-01  2.21364975e-01  1.72218084e-02  2.03562677e-02\n",
      "  3.12033534e-01  2.99072534e-01  9.67799425e-02 -6.95670322e-02\n",
      " -2.61702538e-02  1.18546605e-01  2.48736307e-01  5.93001842e-02\n",
      "  2.05640364e-02  2.20886916e-01  2.06499353e-01  1.00621194e-01\n",
      " -4.01505977e-02 -4.31684405e-03  1.14381537e-01  2.37856448e-01\n",
      "  2.69372165e-02  2.06128322e-02  2.09246442e-01  1.94253460e-01\n",
      "  9.92164016e-02 -4.59975526e-02 -1.52461529e-02  1.17360659e-01\n",
      "  2.26001531e-01  1.88560188e-02  1.98000222e-02  2.17209667e-01\n",
      "  2.15337664e-01  9.94442999e-02  1.16188163e-02  3.10624391e-02\n",
      "  1.16296798e-01  3.44319850e-01  1.32682800e-01  2.01093815e-02\n",
      "  1.70791805e-01  1.54589564e-01  1.00312889e-01 -2.99400836e-02\n",
      " -1.98952854e-04  1.13265693e-01  2.44674951e-01  3.70277762e-02\n",
      "  2.05182172e-02  1.97960481e-01  1.89620897e-01  9.95403826e-02\n",
      " -2.60404050e-02 -1.67986006e-03  1.15979284e-01  2.98557013e-01\n",
      "  4.55064774e-02  1.98393743e-02  2.31753349e-01  2.27241606e-01], \n",
      "EHu=[-0.0199503  -0.6508826  -0.64793277 -0.02113304 -0.09122795 -0.05487394\n",
      " -0.22564948 -0.49637377 -0.03879344 -0.01947386 -0.20710349 -0.21274507\n",
      " -0.0220577  -0.05586517 -0.03015494 -0.23801005 -0.49059236 -0.02797031\n",
      " -0.01996019 -0.22305751 -0.21806335 -0.02199678 -0.04915804 -0.02667421\n",
      " -0.24236017 -0.4088707  -0.02752531 -0.0196437  -0.3770013  -0.3685068\n",
      " -0.02321993 -0.00168365  0.01566553 -0.24145305 -0.4580164  -0.02997899\n",
      " -0.01943594 -0.19155264 -0.18135405 -0.01937872 -0.04314137 -0.01554936\n",
      " -0.24561799 -0.43828672 -0.02758014 -0.01938714 -0.17070305 -0.1602261\n",
      " -0.02078354 -0.03437179 -0.00434643 -0.242639   -0.41612798 -0.02302289\n",
      " -0.02019994 -0.19014394 -0.19828987 -0.02055556 -0.11921895 -0.08784431\n",
      " -0.24370283 -0.49781483 -0.03782189 -0.01989058 -0.092592   -0.08220851\n",
      " -0.01968703 -0.05551463 -0.02557164 -0.24673402 -0.44706827 -0.02696586\n",
      " -0.01948174 -0.14722228 -0.14642525 -0.02045955 -0.06048775 -0.03024077\n",
      " -0.24402034 -0.49130803 -0.03099871 -0.02016059 -0.2130233  -0.213714  ]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "step=1200, train_loss=0.3943968415260315, \n",
      "EHl=[ 0.02062098  0.67490155  0.6700524   0.09839304  0.02775792  0.04147194\n",
      "  0.12581496  0.38961077  0.13300747  0.02048918  0.23058432  0.20458491\n",
      "  0.09770552  0.00533177  0.02492689  0.10654936  0.33953506  0.09528498\n",
      "  0.01941309  0.11288776  0.08867963  0.09814882 -0.02884266  0.01198003\n",
      "  0.10834008  0.29926333  0.04785597  0.02109778  0.14693418  0.11430623\n",
      "  0.09781059 -0.07949254 -0.03214048  0.10807356  0.24766958  0.04513156\n",
      "  0.01948355  0.16101891  0.1330069   0.09790394  0.00806735  0.02422798\n",
      "  0.10943004  0.33221662  0.04623491  0.02038546  0.22483858  0.20129886\n",
      "  0.09884447  0.04099742  0.05336442  0.10616833  0.38910556  0.1422399\n",
      "  0.01999604  0.34310767  0.34017447  0.0970971   0.05311872  0.06523728\n",
      "  0.11010183  0.44614017  0.18527415  0.0199188   0.18451534  0.14968279\n",
      "  0.09740832  0.01582607  0.04934674  0.10570088  0.27713013  0.0858663\n",
      "  0.0202428   0.18708754  0.16257338  0.09872512  0.00708086  0.02118351\n",
      "  0.10108638  0.37476617  0.15977931  0.02078339  0.28550267  0.27833423], \n",
      "EHu=[-0.019379   -0.6874057  -0.67692596 -0.02160695 -0.14261252 -0.10374147\n",
      " -0.23418492 -0.5015021  -0.03107274 -0.0195108  -0.21669304 -0.18035531\n",
      " -0.02229443 -0.10013884 -0.06122017 -0.2534505  -0.49862885 -0.03185678\n",
      " -0.02058689  0.01953983  0.0513587  -0.02185115 -0.05873901 -0.03519595\n",
      " -0.25165963 -0.49560392 -0.03230703 -0.01890218 -0.05694902 -0.00953972\n",
      " -0.02218935  0.01786166  0.04100138 -0.25192618 -0.49090946 -0.02743864\n",
      " -0.02051642 -0.08021581 -0.04296565 -0.02209598 -0.10697007 -0.06734359\n",
      " -0.25056964 -0.49540824 -0.02475822 -0.01961448 -0.20400584 -0.17115402\n",
      " -0.02115551 -0.16826808 -0.12034756 -0.2538314  -0.507117   -0.03852713\n",
      " -0.02000393 -0.44208062 -0.4348042  -0.02290283 -0.18745142 -0.13806933\n",
      " -0.24989778 -0.51095355 -0.03388596 -0.02008116 -0.12412453 -0.07785368\n",
      " -0.02259162 -0.12680405 -0.10318154 -0.25429887 -0.49300742 -0.02027345\n",
      " -0.01975719 -0.13812399 -0.10508418 -0.02127481 -0.10753429 -0.06844121\n",
      " -0.25891334 -0.5046558  -0.03541672 -0.01921657 -0.32635653 -0.310158  ]\n",
      "EH constraints satisfied, stopping training\n",
      "step=1267, train_loss=0.2510066628456116, \n",
      "EHl=[0.02066385 0.6806379  0.67638355 0.0991803  0.04363928 0.05235857\n",
      " 0.1183812  0.4064113  0.09100726 0.01814484 0.20540996 0.18932681\n",
      " 0.09732898 0.02431351 0.04644493 0.10092773 0.36849236 0.08332102\n",
      " 0.02109506 0.32141638 0.29324746 0.10022268 0.05173844 0.06929655\n",
      " 0.109234   0.29370132 0.11798853 0.02056071 0.2764345  0.2589502\n",
      " 0.09893094 0.05855142 0.06793325 0.1029312  0.37469    0.1310342\n",
      " 0.01839725 0.20270307 0.17638633 0.09751432 0.05792081 0.07722885\n",
      " 0.09645021 0.34545067 0.17979267 0.01999895 0.21969017 0.19393829\n",
      " 0.09888175 0.07939271 0.08593109 0.10420275 0.47837964 0.20035237\n",
      " 0.019219   0.3622065  0.34953383 0.09833477 0.06516474 0.07650916\n",
      " 0.10372319 0.41677982 0.10788248 0.01984955 0.20684175 0.18625434\n",
      " 0.10008889 0.00302086 0.02883692 0.09642426 0.38183197 0.1006228\n",
      " 0.01941464 0.25911897 0.23032272 0.09667029 0.04082658 0.04573913\n",
      " 0.09428926 0.36399108 0.16431674 0.0201569  0.31789315 0.30278748], \n",
      "EHu=[-0.01933611 -0.6522252  -0.641338   -0.0208196  -0.11027247 -0.06522286\n",
      " -0.24161857 -0.51376057 -0.02630639 -0.02185515 -0.1069417  -0.0916549\n",
      " -0.02267095 -0.07594281 -0.03968012 -0.25907195 -0.50987583 -0.02696741\n",
      " -0.01890492 -0.32349145 -0.2849357  -0.01977727 -0.12417388 -0.08141172\n",
      " -0.25076574 -0.50323397 -0.01358056 -0.01943925 -0.25001025 -0.22633457\n",
      " -0.02106895 -0.13492137 -0.08387101 -0.2570685  -0.50743175 -0.02583611\n",
      " -0.02160273 -0.09905839 -0.06936193 -0.02248555 -0.13097453 -0.09467572\n",
      " -0.26354945 -0.5044486  -0.02069092 -0.02000103 -0.13674796 -0.10408843\n",
      " -0.02111822 -0.17181861 -0.11814719 -0.25579685 -0.52080697 -0.02650332\n",
      " -0.02078098 -0.41223454 -0.39723623 -0.02166522 -0.14836371 -0.10694748\n",
      " -0.25627643 -0.51574063 -0.01821995 -0.02015042 -0.11032009 -0.08605766\n",
      " -0.01991108 -0.037925   -0.00428718 -0.26357538 -0.5114437  -0.02441168\n",
      " -0.02058534 -0.2135036  -0.17906892 -0.02332965 -0.09896851 -0.05205631\n",
      " -0.26571053 -0.50651824 -0.01970565 -0.01984307 -0.32421625 -0.30097306]\n",
      "eta=[[ 2.1369505e-01 -2.6967463e-03 -3.5747362e-03 ...  7.4600964e-04\n",
      "   1.8957644e-04 -1.3081745e-04]\n",
      " [-3.7573038e-03  1.3352523e-03  8.4054464e-04 ... -4.1314238e-04\n",
      "  -2.1270025e-04 -1.2625764e-03]\n",
      " [-2.8315049e-02  1.7327090e-01 -3.5807244e-02 ... -5.3067892e-03\n",
      "  -5.9797582e-03 -5.9197149e-03]\n",
      " ...\n",
      " [-1.2236739e-02 -1.1478873e-02 -1.2035843e-02 ...  3.1126119e-02\n",
      "  -1.3131188e-01 -1.7598143e-02]\n",
      " [ 4.0679084e-04 -2.3310582e-05  1.4912067e-03 ...  6.3838024e-04\n",
      "  -2.2700510e-04  4.6022651e-01]\n",
      " [ 3.7386134e-04 -2.1488589e-04  1.1652986e-03 ...  6.4479292e-04\n",
      "   7.6392040e-05 -1.5775238e-01]] \n",
      "\n",
      "y=[[(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.30000001, 0.30000001)]\n",
      " [(-0.24000001, 0.24000001)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.90000004, 0.90000004)]\n",
      " [(-0.72000003, 0.72000003)]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.1       , 0.1       )]\n",
      " [(-0.08000001, 0.08000001)]]\n",
      "Saving model to 28-platoon/model.eqx... done.\n",
      "Finished training in 1044.3334965705872 seconds.\n"
     ]
    }
   ],
   "source": [
    "def train(params, optim, steps, minsteps, print_every=1) -> irx.NeuralNetwork :\n",
    "    opt_state = optim.init(eqx.filter(params, eqx.is_array))\n",
    "\n",
    "    for step in range(steps) :\n",
    "        params, opt_state, train_loss, EHval = make_step(params, opt_state)\n",
    "        if (step % print_every) == 0 or (step == steps - 1) :\n",
    "            net, eta, oly = params\n",
    "            net.save()\n",
    "            print(\n",
    "                f'{step=}, train_loss={train_loss.item()}, '\n",
    "                f'\\nEHl={EHval[:len(H)]}, \\nEHu={EHval[len(H):]}'\n",
    "                # f'\\ny={oly_to_y(oly)}'\n",
    "                # f'\\neta={eta} \\n'\n",
    "            )\n",
    "        if (jnp.all(EHval[:len(H)] >= 0) \n",
    "            and jnp.all(EHval[len(H):] <= 0)\n",
    "            and step >= minsteps) :\n",
    "            print('EH constraints satisfied, stopping training')\n",
    "            print(\n",
    "                f'{step=}, train_loss={train_loss.item()}, '\n",
    "                f'\\nEHl={EHval[:len(H)]}, \\nEHu={EHval[len(H):]}'\n",
    "                f'\\neta={eta} \\n'\n",
    "                f'\\ny={oly_to_y(oly)}'\n",
    "            )\n",
    "            return params\n",
    "    \n",
    "    return params\n",
    "\n",
    "t0 = time()\n",
    "net, eta, oly = train((net, eta, oly), optim, 1000000, 100, 100)\n",
    "tf = time()\n",
    "net.save()\n",
    "print(f'Finished training in {tf - t0} seconds.')\n",
    "y = oly_to_y(oly)\n",
    "onp.save(f'{N}-platoon/H.npy', H)\n",
    "onp.save(f'{N}-platoon/ylyu.npy', irx.i2lu(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "if N == 4 :\n",
    "    from pypoman import compute_polytope_vertices, plot_polygon\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"Helvetica\",\n",
    "        \"font.size\": 14\n",
    "    })\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ll = [1., 3., 9, 1.]\n",
    "    cc = ['tab:red', 'tab:blue', 'tab:green', 'tab:orange']\n",
    "\n",
    "    vv = []\n",
    "\n",
    "    for i, l in enumerate(ll) :\n",
    "        vv.append(compute_polytope_vertices(\n",
    "            onp.vstack((-Hblk, Hblk)), onp.concatenate((-y.lower[i*3:i*3+3], y.upper[i*3:i*3+3]))))\n",
    "        plot_polygon(vv[-1], alpha=1., fill=False, linewidth=2., color=cc[i])\n",
    "    # ax.plot(xx[:,i*2], xx[:,i*2+1], label=f'Vehicle {i+1}')\n",
    "\n",
    "    # Get a random vertex from vv\n",
    "    vert = [0,-3,5,3]\n",
    "    print(vv)\n",
    "    x0 = jnp.vstack([vv[i][vert[i]] for i in range(4)]).flatten()\n",
    "    clsys = irx.ControlledSystem(sys, net)\n",
    "    w_map = lambda t,x : jnp.zeros(1)\n",
    "    traj = clsys.compute_trajectory(0., 10., x0, (w_map,), dt=0.01)\n",
    "    tfinite = jnp.where(jnp.isfinite(traj.ts))\n",
    "    xx = traj.ys[tfinite]\n",
    "    for i in range(N) :\n",
    "        ax.plot(xx[:,i*2], xx[:,i*2+1], label=f'Vehicle {i+1}', color=cc[i])\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('4-platoon.pdf')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immrax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
